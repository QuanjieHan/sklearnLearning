{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets # iris and digits datasets for classification, boston house prices dataset for regression\n",
    "import numpy as np\n",
    "iris=datasets.load_iris()  # load datasets\n",
    "X,y=iris.data,iris.target\n",
    "#digits=datasets.load_digits()\n",
    "#print(iris.data)\n",
    "#print(digits.data)\n",
    "#digits.target\n",
    "#print(np.shape(digits.data))\n",
    "#print(digits.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Linear SVC is  0.9210526315789473\n",
      "The accuracy of kNN classifier is  0.9473684210526315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00         8\n",
      " versicolor       0.79      1.00      0.88        11\n",
      "  virginica       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.94      0.92      0.92        38\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       0.85      1.00      0.92        11\n",
      "          2       1.00      0.89      0.94        19\n",
      "\n",
      "avg / total       0.96      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# algorithm configuration\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=33,test_size=0.25)\n",
    "clf_svm=svm.SVC(gamma=0.001,C=100)\n",
    "clf_kNN=KNeighborsClassifier(n_neighbors=5)\n",
    "clf_svm.fit(X_train,y_train)\n",
    "clf_kNN.fit(X_train,y_train)\n",
    "ypred_svm=clf_svm.predict(X_test)\n",
    "ypred_kNN=clf_kNN.predict(X_test)\n",
    "accuracy_iris_svm=accuracy_score(y_test,ypred_svm)\n",
    "accuracy_iris_kNN=accuracy_score(y_test,ypred_kNN)\n",
    "print('The accuracy of Linear SVC is ', accuracy_iris_svm)\n",
    "print('The accuracy of kNN classifier is ', accuracy_iris_kNN)\n",
    "print(classification_report(y_test,ypred_svm,target_names=iris.target_names.astype(str)))\n",
    "print(classification_report(y_test,ypred_kNN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       1.00      1.00      1.00        19\n",
      "\n",
      "avg / total       1.00      1.00      1.00        38\n",
      "\n",
      "0.47368421052631576\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      1.00      0.44         8\n",
      "          1       0.00      0.00      0.00        11\n",
      "          2       1.00      0.53      0.69        19\n",
      "\n",
      "avg / total       0.56      0.47      0.44        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songweiwei/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/songweiwei/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression and SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr=LogisticRegression()\n",
    "sgdc=SGDClassifier()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "lr_y_predict=lr.predict(X_test)\n",
    "sgdc.fit(X_train,y_train)\n",
    "sgdc_y_predict=sgdc.predict(X_test)\n",
    "print(lr.score(X_test,y_test))\n",
    "print(classification_report(y_test,lr_y_predict))\n",
    "print(sgdc.score(X_test,y_test))\n",
    "print(classification_report(y_test,sgdc_y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "0.8947368421052632\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       0.73      1.00      0.85        11\n",
      "          2       1.00      0.79      0.88        19\n",
      "\n",
      "avg / total       0.92      0.89      0.90        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tree based classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier()\n",
    "print(dtc)\n",
    "dtc.fit(X_train,y_train)\n",
    "dtc_predict=dtc.predict(X_test)\n",
    "print (dtc.score(X_test,y_test))\n",
    "print(classification_report(y_test,dtc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier  ( Emsemble model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.8947368421052632\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       0.73      1.00      0.85        11\n",
      "          2       1.00      0.79      0.88        19\n",
      "\n",
      "avg / total       0.92      0.89      0.90        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "print(rfc)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict=rfc.predict(X_test)\n",
    "print(rfc.score(X_test,y_test))\n",
    "print(classification_report(y_test,rfc_predict))\n",
    "#help(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "0.9210526315789473\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       0.79      1.00      0.88        11\n",
      "          2       1.00      0.84      0.91        19\n",
      "\n",
      "avg / total       0.94      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc=GradientBoostingClassifier()\n",
    "print(gbc)\n",
    "gbc.fit(X_train,y_train)\n",
    "gbc_predict=gbc.predict(X_test)\n",
    "print(gbc.score(X_test,y_test))\n",
    "print(classification_report(y_test,gbc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "0.9473684210526315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       0.85      1.00      0.92        11\n",
      "          2       1.00      0.89      0.94        19\n",
      "\n",
      "avg / total       0.96      0.95      0.95        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songweiwei/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/songweiwei/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgbc=XGBClassifier()\n",
    "print(xgbc)\n",
    "xgbc.fit(X_train,y_train)\n",
    "xgbc_predict=xgbc.predict(X_test)\n",
    "print(xgbc.score(X_test,y_test))\n",
    "print(classification_report(y_test,xgbc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
